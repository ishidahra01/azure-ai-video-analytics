{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Video Analytics Demo\n",
    "\n",
    "## Create Azure AI Search and retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    AIServicesVisionParameters,\n",
    "    AIServicesVisionVectorizer,\n",
    "    AIStudioModelCatalogName,\n",
    "    AzureMachineLearningVectorizer,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIModelName,\n",
    "    AzureOpenAIParameters,\n",
    "    BlobIndexerDataToExtract,\n",
    "    BlobIndexerParsingMode,\n",
    "    CognitiveServicesAccountKey,\n",
    "    DefaultCognitiveServicesAccount,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    FieldMapping,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    IndexerExecutionStatus,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    ScalarQuantizationCompressionConfiguration,\n",
    "    ScalarQuantizationParameters,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataIdentity,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerSkillset,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    "    SimpleField,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    VectorSearchProfile,\n",
    "    VisionVectorizeSkill\n",
    ")\n",
    "from azure.search.documents.models import (\n",
    "    HybridCountAndFacetMode,\n",
    "    HybridSearch,\n",
    "    SearchScoreThreshold,\n",
    "    VectorizableTextQuery,\n",
    "    VectorizableImageBinaryQuery,\n",
    "    VectorizableImageUrlQuery,\n",
    "    VectorSimilarityThreshold,\n",
    ")\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display, HTML\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "AZURE_AI_VISION_API_KEY = os.getenv(\"AZURE_AI_VISION_API_KEY\")\n",
    "AZURE_AI_VISION_ENDPOINT = os.getenv(\"AZURE_AI_VISION_ENDPOINT\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "BLOB_CONNECTION_STRING = os.getenv(\"BLOB_CONNECTION_STRING\")\n",
    "BLOB_CONTAINER_NAME = os.getenv(\"BLOB_CONTAINER_NAME\")\n",
    "BLOB_CONNECTION_MANAGEDID_STRING=os.getenv(\"BLOB_CONNECTION_MANAGEDID_STRING\")\n",
    "INDEX_NAME = \"azure-ai-video-analytics-0728\"\n",
    "AZURE_SEARCH_ADMIN_KEY = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-specified parameter\n",
    "USE_AAD_FOR_SEARCH = False  # Set this to False to use API key for authentication\n",
    "\n",
    "def authenticate_azure_search(api_key=None, use_aad_for_search=False):\n",
    "    if use_aad_for_search:\n",
    "        print(\"Using AAD for authentication.\")\n",
    "        credential = DefaultAzureCredential()\n",
    "    else:\n",
    "        print(\"Using API keys for authentication.\")\n",
    "        if api_key is None:\n",
    "            raise ValueError(\"API key must be provided if not using AAD for authentication.\")\n",
    "        credential = AzureKeyCredential(api_key)\n",
    "    return credential\n",
    "\n",
    "azure_search_credential = authenticate_azure_search(api_key=AZURE_SEARCH_ADMIN_KEY, use_aad_for_search=USE_AAD_FOR_SEARCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a blob data source connector on Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_update_data_source(indexer_client, container_name, connection_string, index_name):\n",
    "    \"\"\"\n",
    "    Create or update a data source connection for Azure AI Search.\n",
    "    \"\"\"\n",
    "    container = SearchIndexerDataContainer(name=container_name, query=\"metadata\")\n",
    "    data_source_connection = SearchIndexerDataSourceConnection(\n",
    "        name=f\"{index_name}-blob\",\n",
    "        type=\"azureblob\",\n",
    "        connection_string=connection_string,\n",
    "        container=container\n",
    "    )\n",
    "    try:\n",
    "        indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "        print(f\"Data source '{index_name}-blob' created or updated successfully.\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to create or update data source due to error: {e}\")\n",
    "\n",
    "# Create a SearchIndexerClient instance\n",
    "indexer_client = SearchIndexerClient(AZURE_SEARCH_ENDPOINT, azure_search_credential)\n",
    "\n",
    "# Call the function to create or update the data source\n",
    "create_or_update_data_source(indexer_client, f\"{BLOB_CONTAINER_NAME}\", BLOB_CONNECTION_MANAGEDID_STRING, INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fields():\n",
    "    \"\"\"Creates the fields for the search index based on the specified schema.\"\"\"\n",
    "    return [\n",
    "        SimpleField(\n",
    "            name=\"id\", type=SearchFieldDataType.String, key=True, filterable=True\n",
    "        ),\n",
    "        SearchField(name=\"caption\", type=SearchFieldDataType.String, searchable=True),\n",
    "        SearchField(name=\"video_filename\", type=SearchFieldDataType.String, searchable=True),\n",
    "        SearchField(name=\"frame_filename\", type=SearchFieldDataType.String, searchable=True),\n",
    "        SearchField(name=\"frame_url\", type=SearchFieldDataType.String, searchable=True),\n",
    "        SearchField(name=\"frame_number\", type=SearchFieldDataType.String, searchable=True),\n",
    "        SearchField(name=\"timestamp\", type=SearchFieldDataType.String, searchable=True),\n",
    "        SearchField(\n",
    "            name=\"captionVector\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            vector_search_dimensions=1024,\n",
    "            vector_search_profile_name=\"myHnswProfile\",\n",
    "            stored=False,\n",
    "            searchable=True\n",
    "        ),\n",
    "        SearchField(\n",
    "            name=\"imageVector\",\n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "            vector_search_dimensions=1024,\n",
    "            vector_search_profile_name=\"myHnswProfile\",\n",
    "            stored=False,\n",
    "            searchable=True\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "def create_vector_search_configuration():\n",
    "    \"\"\"Creates the vector search configuration.\"\"\"\n",
    "    return VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"myHnsw\",\n",
    "                parameters=HnswParameters(\n",
    "                    m=4,\n",
    "                    ef_construction=400,\n",
    "                    ef_search=500,\n",
    "                    metric=VectorSearchAlgorithmMetric.COSINE,\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        compressions=[\n",
    "            ScalarQuantizationCompressionConfiguration(\n",
    "                name=\"myScalarQuantization\",\n",
    "                rerank_with_original_vectors=True,\n",
    "                default_oversampling=10,\n",
    "                parameters=ScalarQuantizationParameters(quantized_data_type=\"int8\"),\n",
    "            )\n",
    "        ],\n",
    "        vectorizers=[\n",
    "            AIServicesVisionVectorizer(\n",
    "                name=\"myAIServicesVectorizer\",\n",
    "                kind=\"aiServicesVision\",\n",
    "                ai_services_vision_parameters=AIServicesVisionParameters(\n",
    "                    model_version=\"2023-04-15\",\n",
    "                    resource_uri=AZURE_AI_VISION_ENDPOINT,\n",
    "                    api_key=AZURE_AI_VISION_API_KEY,\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"myHnswProfile\",\n",
    "                algorithm_configuration_name=\"myHnsw\",\n",
    "                compression_configuration_name=\"myScalarQuantization\",\n",
    "                vectorizer=\"myAIServicesVectorizer\",\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def create_search_index(index_client, index_name, fields, vector_search):\n",
    "    \"\"\"Creates or updates a search index.\"\"\"\n",
    "    index = SearchIndex(\n",
    "        name=index_name,\n",
    "        fields=fields,\n",
    "        vector_search=vector_search,\n",
    "    )\n",
    "    index_client.create_or_update_index(index=index)\n",
    "\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT, credential=azure_search_credential\n",
    ")\n",
    "fields = create_fields()\n",
    "vector_search = create_vector_search_configuration()\n",
    "\n",
    "# Create the search index with the adjusted schema\n",
    "create_search_index(index_client, INDEX_NAME, fields, vector_search)\n",
    "print(f\"Created index: {INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Skillset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_text_embedding_skill():\n",
    "    return VisionVectorizeSkill(\n",
    "        name=\"text-embedding-skill\",\n",
    "        description=\"Skill to generate embeddings for text via Azure AI Vision\",\n",
    "        context=\"/document\",\n",
    "        model_version=\"2023-04-15\",\n",
    "        inputs=[InputFieldMappingEntry(name=\"text\", source=\"/document/caption\")],\n",
    "        outputs=[OutputFieldMappingEntry(name=\"vector\", target_name=\"captionVector\")],\n",
    "    )\n",
    "\n",
    "def create_image_embedding_skill():\n",
    "    return VisionVectorizeSkill(\n",
    "        name=\"image-embedding-skill\",\n",
    "        description=\"Skill to generate embeddings for image via Azure AI Vision\",\n",
    "        context=\"/document\",\n",
    "        model_version=\"2023-04-15\",\n",
    "        inputs=[\n",
    "\t\t\tInputFieldMappingEntry(name=\"url\", source=\"/document/frame_url_with_sas\")\n",
    "        ],\n",
    "        outputs=[OutputFieldMappingEntry(name=\"vector\", target_name=\"imageVector\")],\n",
    "    )\n",
    "\n",
    "def create_skillset(client, skillset_name, text_embedding_skill, image_embedding_skill):\n",
    "    skillset = SearchIndexerSkillset(\n",
    "        name=skillset_name,\n",
    "        description=\"Skillset for generating embeddings\",\n",
    "        skills=[text_embedding_skill, image_embedding_skill],\n",
    "        cognitive_services_account=CognitiveServicesAccountKey(\n",
    "            key=AZURE_AI_VISION_API_KEY,\n",
    "            description=\"AI Vision Multi Service Account in West US\",\n",
    "        ),\n",
    "    )\n",
    "    client.create_or_update_skillset(skillset)\n",
    "\n",
    "client = SearchIndexerClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT, credential=azure_search_credential\n",
    ")\n",
    "skillset_name = f\"{INDEX_NAME}-skillset\"\n",
    "text_embedding_skill = create_text_embedding_skill()\n",
    "image_embedding_skill = create_image_embedding_skill()\n",
    "\n",
    "create_skillset(client, skillset_name, text_embedding_skill, image_embedding_skill)\n",
    "print(f\"Created skillset: {skillset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_run_indexer(indexer_client, indexer_name, skillset_name, index_name, data_source_name):\n",
    "    indexer = SearchIndexer(\n",
    "        name=indexer_name,\n",
    "        description=\"Indexer to index documents and generate embeddings\",\n",
    "        skillset_name=skillset_name,\n",
    "        target_index_name=index_name,\n",
    "        data_source_name=data_source_name,\n",
    "        parameters=IndexingParameters(\n",
    "            configuration=IndexingParametersConfiguration(\n",
    "                parsing_mode=BlobIndexerParsingMode.JSON_ARRAY,\n",
    "                query_timeout=None,\n",
    "            ),\n",
    "        ),\n",
    "        field_mappings=[\n",
    "            # FieldMapping(source_field_name=\"id\", target_field_name=\"id\"),\n",
    "            FieldMapping(source_field_name=\"video_filename\", target_field_name=\"video_filename\"),\n",
    "            FieldMapping(source_field_name=\"frame_filename\", target_field_name=\"frame_filename\"),\n",
    "            FieldMapping(source_field_name=\"frame_url\", target_field_name=\"frame_url\"),\n",
    "            FieldMapping(source_field_name=\"frame_number\", target_field_name=\"frame_number\"),\n",
    "            FieldMapping(source_field_name=\"timestamp\", target_field_name=\"timestamp\"),\n",
    "        ],\n",
    "        output_field_mappings=[\n",
    "            FieldMapping(source_field_name=\"/document/captionVector\", target_field_name=\"captionVector\"),\n",
    "            FieldMapping(source_field_name=\"/document/imageVector\", target_field_name=\"imageVector\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    indexer_client.create_or_update_indexer(indexer)\n",
    "    print(f\"{indexer_name} created or updated.\")\n",
    "\n",
    "    indexer_client.run_indexer(indexer_name)\n",
    "    print(f\"{indexer_name} is running. If queries return no results, please wait a bit and try again.\")\n",
    "\n",
    "indexer_client = SearchIndexerClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT, credential=azure_search_credential\n",
    ")\n",
    "data_source_name = f\"{INDEX_NAME}-blob\"\n",
    "indexer_name = f\"{INDEX_NAME}-indexer\"\n",
    "\n",
    "create_and_run_indexer(indexer_client, indexer_name, skillset_name, INDEX_NAME, data_source_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "# Exract filename from URL\n",
    "def extract_filename_from_url(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    return parsed_url.path.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient, BlobClient, generate_blob_sas, BlobSasPermissions\n",
    "import datetime\n",
    "\n",
    "def get_url_with_sas(blob_url):\n",
    "\t# Setting for Azure Blob Storage\n",
    "\tblob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
    "\n",
    "\tblob_name = extract_filename_from_url(blob_url)\n",
    "\tblob_client = blob_service_client.get_blob_client(container=BLOB_CONTAINER_NAME, blob=f\"images/{blob_name}\")\n",
    " \n",
    "\tstart_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "\texpiry_time = start_time + datetime.timedelta(days=1)\n",
    "\n",
    "\tsas_token = generate_blob_sas(\n",
    "\t\taccount_name=blob_client.account_name,\n",
    "\t\tcontainer_name=blob_client.container_name,\n",
    "\t\tblob_name=f\"images/{blob_name}\",\n",
    "\t\taccount_key=blob_service_client.credential.account_key,\n",
    "\t\tpermission=BlobSasPermissions(read=True),\n",
    "\t\texpiry=expiry_time,\n",
    "\t\tstart=start_time\n",
    "\t)\n",
    "\treturn f\"{blob_url}?{sas_token}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SearchClient\n",
    "search_client = SearchClient(\n",
    "    AZURE_SEARCH_ENDPOINT,\n",
    "    index_name=INDEX_NAME,\n",
    "    credential=azure_search_credential,\n",
    ")\n",
    "\n",
    "# Define the query\n",
    "query = \"Azure AI のアップデート\"\n",
    "\n",
    "vector_query_caption = VectorizableTextQuery(\n",
    "    text=query,\n",
    "    k_nearest_neighbors=10,\n",
    "    fields=\"captionVector\",\n",
    ")\n",
    "\n",
    "vector_query_image = VectorizableTextQuery(\n",
    "    text=query,\n",
    "    k_nearest_neighbors=10,\n",
    "    fields=\"imageVector\",\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query_caption, vector_query_image],\n",
    "    top=10\n",
    ")\n",
    "\n",
    "frame_timestamps = []\n",
    "results_history = []\n",
    "\n",
    "# Print the results\n",
    "for result in results:\n",
    "    results_history.append(result)\n",
    "    print(f\"Caption: {result['caption']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"timestamp: {result['timestamp']}\")\n",
    "    frame_timestamps.append(round(float(result[\"timestamp\"])))\n",
    "    frame_url_with_sas = get_url_with_sas(result[\"frame_url\"])\n",
    "    display(HTML(f'<img src=\"{frame_url_with_sas}\" style=\"width:200px;\"/>'))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "search_history.append({\n",
    "\t\"query\": query,\n",
    "\t\"results\": results_history\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Highlight Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_highlight_frames(video_path, frame_timestamps, pre_post_seconds, fps):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_indices = [int(ts * fps) for ts in frame_timestamps]\n",
    "    highlight_frames = []\n",
    "\n",
    "    for idx in frame_indices:\n",
    "        start_frame = max(0, idx - int(pre_post_seconds * fps))\n",
    "        end_frame = idx + int(pre_post_seconds * fps)\n",
    "        \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        for frame_num in range(start_frame, end_frame + 1):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            highlight_frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return highlight_frames\n",
    "\n",
    "def create_video_from_frames(frames, output_video_path, fps=30, frame_size=None):\n",
    "    if frame_size is None:\n",
    "        frame_size = (frames[0].shape[1], frames[0].shape[0])\n",
    "        \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 'mp4v' is the MP4 codec\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, frame_size)\n",
    "\n",
    "    for frame in frames:\n",
    "        resized_frame = cv2.resize(frame, frame_size)\n",
    "        out.write(resized_frame)\n",
    "\n",
    "    out.release()\n",
    "    print(f\"Video saved to {output_video_path}\")\n",
    "\n",
    "# Path to the video file and highlight timestamps (in seconds)\n",
    "video_path = 'data/keynote_ms_build_2024.mp4'\n",
    "pre_post_seconds = 5  # Include frames 5 seconds before and after\n",
    "fps = 30\n",
    "\n",
    "# Extract highlight frames\n",
    "highlight_frames = extract_highlight_frames(video_path, frame_timestamps, pre_post_seconds, fps)\n",
    "\n",
    "# Path to the output video\n",
    "output_video_path = 'output_video/highlight_video.mp4'\n",
    "\n",
    "# Create the video\n",
    "create_video_from_frames(highlight_frames, output_video_path, fps=fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "#Note: This code sample requires OpenAI Python library version 1.0.0 or higher.\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "\n",
    "def chatcompletion(message_text):\n",
    "\tclient = AzureOpenAI(\n",
    "\tazure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "\tapi_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "\tapi_version=\"2024-02-01\"\n",
    "\t)\n",
    "\n",
    "\n",
    "\tcompletion = client.chat.completions.create(\n",
    "\t\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\t\tmessages = message_text,\n",
    "\t\ttemperature=0,\n",
    "\t\tmax_tokens=800,\n",
    "\t\ttop_p=0.95,\n",
    "\t\tfrequency_penalty=0,\n",
    "\t\tpresence_penalty=0,\n",
    "\t\tstop=None\n",
    "\t\t)\n",
    "\tprint(completion.choices[0].message.content)\n",
    "\treturn completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate description of hightlight scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "Generate description of highlight scene from search results.\n",
    "\n",
    "Search results: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "message_text = [\n",
    "\t{\"role\":\"system\",\"content\":system_message},\n",
    "\t{\"role\":\"user\",\"content\": [\n",
    "\t]}\n",
    "]\n",
    "for search_results in search_history:\n",
    "    \n",
    "\tfor entry in search_results[\"results\"]:\n",
    "\t\tmessage_text[1][\"content\"].append(\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\"content\": entry[\"caption\"]\n",
    "\t\t\t}\n",
    "\t\t)\n",
    "\t\tmessage_text[1][\"content\"].append(\n",
    "\t\t\t{\n",
    "\t\t\t\t\"type\": \"image_url\",\n",
    "\t\t\t\t\"image_url\": {\n",
    "\t\t\t\t\t\"url\": get_url_with_sas(entry[\"frame_url\"])\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t)\n",
    "\n",
    "\n",
    "completion = chatcompletion(message_text)\n",
    "print(f\"Description of highlight scene: {completion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBD: Edit pick-up frames with interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to revise system prompt for editting pick-up frames.\n",
    "\n",
    "**Note that cells after this are incomplete.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"講演者をアップ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "Generate standalone search queries for image searches from user prompts.\n",
    "You need to integreate previous queries and the latest query.\n",
    "\n",
    "# Previous query\n",
    "{search_history[0][\"query\"]}\n",
    "\n",
    "# Latest query\n",
    "{user_prompt}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_message = f\"\"\"\n",
    "New search query:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "message_text = [\n",
    "\t{\"role\":\"system\",\"content\":system_message},\n",
    "\t{\"role\":\"user\",\"content\": [\n",
    "\t\t{\n",
    "\t\t\t\"type\": \"text\",\n",
    "\t\t\t\"content\": user_message\n",
    "\t\t},\n",
    "\t]}\n",
    "]\n",
    "\n",
    "refine_query = chatcompletion(message_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_query = user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_caption = VectorizableTextQuery(\n",
    "    text=refine_query,\n",
    "    k_nearest_neighbors=10,\n",
    "    fields=\"captionVector\",\n",
    ")\n",
    "\n",
    "vector_query_image = VectorizableTextQuery(\n",
    "    text=refine_query,\n",
    "    k_nearest_neighbors=10,\n",
    "    fields=\"imageVector\",\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "results = search_client.search(\n",
    "    search_text=refine_query,\n",
    "    vector_queries=[vector_query_caption, vector_query_image],\n",
    "    top=10\n",
    ")\n",
    "\n",
    "frame_timestamps = []\n",
    "results_history = []\n",
    "\n",
    "# Print the results\n",
    "for result in results:\n",
    "    results_history.append(result)\n",
    "    print(f\"Caption: {result['caption']}\")\n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"timestamp: {result['timestamp']}\")\n",
    "    frame_timestamps.append(round(float(result[\"timestamp\"])))\n",
    "    frame_url_with_sas = get_url_with_sas(result[\"frame_url\"])\n",
    "    display(HTML(f'<img src=\"{frame_url_with_sas}\" style=\"width:200px;\"/>'))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "search_history.append({\n",
    "\t\"query\": refine_query,\n",
    "\t\"results\": results_history\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New highlight Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "# Your tasks\n",
    "- You need to pick up 10 frames from the search results.\n",
    "- You must output the original JSON data format and key-value pair.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_message = f\"\"\"\n",
    "# Search results\n",
    "{search_history}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "message_text = [\n",
    "\t{\"role\":\"system\",\"content\":system_message},\n",
    "\t{\"role\":\"user\",\"content\": [\n",
    "\t\t{\n",
    "\t\t\t\"type\": \"text\",\n",
    "\t\t\t\"content\": user_message\n",
    "\t\t},\n",
    "\t]}\n",
    "]\n",
    "\n",
    "aoai_client = AzureOpenAI(\n",
    "\tazure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "\tapi_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "\tapi_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "refine_results = aoai_client.chat.completions.create(\n",
    "\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\tmessages = message_text,\n",
    "\tresponse_format={\"type\": \"json_object\"},\n",
    "\ttemperature=0,\n",
    "\tmax_tokens=800,\n",
    "\ttop_p=0.95,\n",
    "\tfrequency_penalty=0,\n",
    "\tpresence_penalty=0,\n",
    "\tstop=None\n",
    "\t)\n",
    "print(refine_results.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動画ファイルのパスとハイライトのタイムスタンプ（秒単位）\n",
    "video_path = 'data/keynote_ms_build_2024.mp4'\n",
    "pre_post_seconds = 5  # 前後5秒のフレームを含める\n",
    "fps = 30\n",
    "\n",
    "# ハイライトフレームを抽出\n",
    "highlight_frames = extract_highlight_frames(video_path, frame_timestamps, pre_post_seconds, fps)\n",
    "\n",
    "# 出力動画のパス\n",
    "output_video_path = 'highlight_video.mp4'\n",
    "\n",
    "# 動画を作成\n",
    "create_video_from_frames(highlight_frames, output_video_path, fps=fps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
